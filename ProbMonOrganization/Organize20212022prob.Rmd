---
title: "Organize 2019-2020 Probmon Sites"
author: "Emma Jones"
date: "10/28/2021"
output: html_document
---

## Background

This script walks users through the process of identifying which stations sampled in 2019-2020 need watersheds delineated, delineates the needed sites, and how to run subsequent landcover analyses for 2022IR report.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(tidyverse)
library(sf)
library(readxl)

source('../organizeShapefiles.R')
```

Below is the final 2021-2022 dataset filtered by what was sampled (wadeable and boatable combined for delineation purposes).

```{r}
stations <- bind_rows(
  read_excel('C:/Users/wmu43954/OneDrive - Commonwealth of Virginia/Freshwater ProbMon/IR2024/Wadeable_ProbMon2021-2022.xlsx',
                                  #'originalData/Wadeable_ProbMon2021-2022.xlsx', # or from here for local archiving
                                  sheet = 'Sheet1') %>% 
  filter(status == 'TS'), # keep only wadeable sites that were sampled for data querying,
  read_excel('C:/Users/wmu43954/OneDrive - Commonwealth of Virginia/Freshwater ProbMon/IR2024/Wadeable_ProbMon2021-2022.xlsx',
                                  #'originalData/Wadeable_ProbMon2021-2022.xlsx', # or from here for local archiving
                                  sheet = 'Sheet1') %>% 
    filter(status %in% c('NT') & str_detect(comment, '(sampled)')) %>% 
    filter(!str_detect(comment, 'not sampled'))) %>% 
  dplyr::select(StationID, Year, StationID_Trend, Longitude, Latitude)

```


Which stations actually need watershed info?

```{r spatial info already available}
watersheds <- #st_read('D:/evjones/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/Watersheds.gdb', 'AllWatersheds_through2016') %>% 
  st_read('C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/Watersheds.gdb', 'AllWatersheds_through2020') %>% 
  filter(StationID %in% stations$StationID)

# so what isn't in there?
missingWatersheds <- filter(stations, ! StationID %in% watersheds$StationID) 

```




Bring in autodelineation functions

```{r bring in autodelineation functions}
source('../ConserveVA/methods/StreamStatsAutoDelineation.R')
```


### Delineate watersheds

```{r delineate watersheds}
streamStatsResults <- streamStats_Delineation(state= 'VA',
                                      longitude = missingWatersheds$Longitude, 
                                      latitude = missingWatersheds$Latitude, 
                                      UID = missingWatersheds$StationID)
```

    + Then we need to organize these files and check they delineated properly.
    
```{r organize spatial results}
# organize into appropriate files, lossy move here- automatically removes sites with no data
watersheds <- streamStatsResults$polygon %>%
  reduce(rbind) %>%
  arrange(UID)
points <- streamStatsResults$point %>%
  reduce(rbind) %>%
  arrange(UID)
```
    
    + Run back out to streamstats and get anyone that is missing
    
```{r fix missing sites (rerun as necessary)}
# fix anything that is missing
if(nrow(points) != nrow(watersheds) | nrow(missingWatersheds) != nrow(watersheds)){
  missing <- unique(
    c(as.character(points$UID[!(points$UID %in% watersheds$UID)]),
      as.character(missingWatersheds$StationID[!(missingWatersheds$StationID %in% watersheds$UID)])))
  missingDat <- filter(missingWatersheds, StationID %in% missing)
  
  #remove missing site from the paired dataset
  points <- filter(points, ! UID %in% missing)
  watersheds <- filter(watersheds, ! UID %in% missing)
  
  dat <- streamStats_Delineation(state= 'VA', 
                                 longitude = missingDat$Longitude, 
                                 latitude = missingDat$Latitude, 
                                 UID = missingDat$StationID)
  
  watersheds_missing <- dat$polygon %>%
    reduce(rbind)
  
  points_missing <- dat$point %>%
    reduce(rbind)
  
  watersheds <- rbind(watersheds, watersheds_missing) %>%
    arrange(UID)
  
  points <- rbind(points, points_missing) %>%
    arrange(UID)
  
  rm(missingDat); rm(dat); rm(watersheds_missing); rm(points_missing)
}

```
   
   
   
QA can be done in R, but with so many it is faster to do in ArcGIS right now.

Bring in somewhat consolidated (Fall 2019 only) bio reports that link StationID to stream order for QA.

```{r stream order}
orderInfo <-bind_rows(
  read_excel('C:/Users/wmu43954/OneDrive - Commonwealth of Virginia/Freshwater ProbMon/2021/Prob2021_RegionalResults_EVJ.xlsx',
                                  sheet = 'All Prob', skip = 2) %>% 
    dplyr::select(StationID = `DEQ StationID`, `Stream Order` = SO) %>% 
    mutate(`Stream Order` = as.numeric(`Stream Order`)),
  left_join(
    read_excel('C:/Users/wmu43954/OneDrive - Commonwealth of Virginia/Freshwater ProbMon/2022/RegionalResults2022.xlsx',
               sheet = 'SampledSites') %>% 
      dplyr::select(StationID, siteID),
    read_excel('C:/Users/wmu43954/OneDrive - Commonwealth of Virginia/Freshwater ProbMon/2022/RegionalResults2022.xlsx',
               sheet = 'All2022ProbSites') %>% 
      dplyr::select(siteID,  `Stream Order` = SO),
    by = 'siteID') %>% 
    dplyr::select(StationID, `Stream Order`)) %>%  
  dplyr::select(StationID, `Stream Order`) %>% 
  filter(! is.na(StationID) ) %>% 
  filter( ! is.na(`Stream Order`))
  

watersheds <- left_join(watersheds, orderInfo, by = c('UID' = 'StationID')) %>%
  dplyr::select(UID,  `Stream Order`, everything()) %>% 
  filter(!is.na(UID))

```


```{r}
st_write(points, 'C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/YearlyAnalyses/20212022_StreamStats/rawPoints.shp')
st_write(watersheds, 'C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/YearlyAnalyses/20212022_StreamStats/rawWatersheds.shp')
```


### Combine fixed watersheds

After going through each watershed in the dataset above, deleting all incorrect watersheds, delineating manually in streamstats, and moving those correct watersheds into C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/YearlyAnalyses/20212022_StreamStats/, we need to combine all the correct watersheds into a single file and then add those sites to a new featureclass in the C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/Watersheds.gdb geodatabase.

```{r bring in fixed watersheds}
# Where did you save files relative to the working directory?
savedHere <- 'C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/YearlyAnalyses/20212022_StreamStats/correctedWatersheds'

# read in new watersheds after manual QA
shapes <- gsub('.prj','',list.files( savedHere, pattern="*.prj", full.names=F))
filenames <- paste0(savedHere, '/',shapes, '.shp')
  
# read in shapefiles and organize
newSheds <- filenames %>%
  map(st_read) %>%
  map2(shapes,~mutate(.x,UID=.y)) %>% # make a StationID column
  map(~dplyr::select(.,UID)) %>%
  reduce(rbind) 

newSheds <- left_join(newSheds, orderInfo, by = c('UID' = 'StationID'))

# Combine with QAed watersheds
watersheds <- st_read('C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/YearlyAnalyses/20212022_StreamStats/rawWatershedsFinalList.shp') %>% 
  rename(`Stream Order` = StrmOrd) %>% 
  rbind(newSheds) %>%
  arrange(UID)

st_write(watersheds, 'C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/YearlyAnalyses/20212022_StreamStats/rawWatershedsFinalListQAed.shp')
watersheds %>% dplyr::select(StationID = UID) %>% st_write('C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/YearlyAnalyses/20212022_StreamStats/rawWatershedsFinalListQAed_tocombinewithGeodatabase.shp')

```
 
Now combine with all previous watersheds into a single geodatabase. Had to do it in Arc Pro bc licensing. 

```{r}
IR2024 <-  st_read('C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/Watersheds.gdb', 'AllWatersheds_through2022') 
IR2022 <-  st_read('C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/Watersheds.gdb', 'AllWatersheds_through2020') 
missing$StationID 
IR2024$StationID %>% tail(100)

```




### Run landcover assessment

First bring in QAed watersheds and identify which watersheds require landcover data. Make sure no one is missing.

```{r QAed watersheds}
QAwatersheds <- st_read('C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/Watersheds.gdb', 'AllWatersheds_through2022') 
stations$StationID[! stations$StationID %in% QAwatersheds$StationID]
  filter(QAwatersheds,StationID %in% missingWatersheds$StationID)
```
Now run landcover analysis in C:\HardDriveBackup\R\GitHub\LandcoverAnalysis\ProbMonOrganization\landcoverAnalysis_20212022.R

```{r landcover analysis}
#source('C:\HardDriveBackup\R\GitHub\LandcoverAnalysis\ProbMonOrganization\landcoverAnalysis_20212022.R')
```























# first attempt with phab database



Right now there is no official 2019-2020 sampled dataset so working with the what is in the Phab database as a starting point.

```{r phab sites new}
phab <- readxl::read_excel('C:/HardDriveBackup/ProbMon/2019/Reach.xlsx') %>% 
  filter(Date > as.Date("2018-12-31")) %>% 
  
  filter(StationID %in% c('1AGO039.69' , '4ASRE069.63', '2-POT0.38.71', '9CVR004.86', '8XIW000.55',
                          '9LRR012.30', '9XBB000.86'))

  
  mutate(`StationID` = case_when(StationID == '1AGO039.69' ~ '1AGOO039.63',
                                 StationID == '4ASRE069.63' ~ '4ASRE063.69',
                                 StationID == '2-POT0.38.71' ~ '2-POT038.71',
                                 StationID == '9CVR004.86' ~ '9-CVR004.86',
                                 StationID == '8XIW000.55' ~ '8-XIW000.55',
                                 StationID == '9LRR012.30' ~ '9-LRR012.30',
                                 StationID == '9XBB000.86' ~ '9-XBB000.86',
                                 TRUE ~ as.character(StationID) )) 
```

### Connect to pinned data to get site lat/lngs from CEDS.

```{r pinned data}
library(pool)
library(pins)
library(config)

# get configuration settings
conn <- config::get("connectionSettings")

# use API key to register board
board_register_rsconnect(key = conn$CONNECT_API_KEY,  #Sys.getenv("CONNECT_API_KEY"),
                          server = conn$CONNECT_SERVER)#Sys.getenv("CONNECT_SERVER"))

stations <- pin_get('ejones/WQM-Sta-GIS-View-Stations',  board = "rsconnect") %>% 
  filter(Station_Id %in% phab$StationID)

# Quick QA, which stations are in phab database but not in CEDS?
stationIssues <- phab$StationID[! phab$StationID %in% stations$Station_Id]

filter(phab, StationID %in% stationIssues) %>% 
  mutate(`Real StationID` = case_when(StationID == '1AGO039.69' ~ '1AGOO039.63',
                                      StationID == '4ASRE069.63' ~ '4ASRE063.69',
                                      StationID == '2-POT0.38.71' ~ '2-POT038.71',
                                      StationID == '9CVR004.86' ~ '9-CVR004.86',
                                      StationID == '8XIW000.55' ~ '8-XIW000.55',
                                      StationID == '9LRR012.30' ~ '9-LRR012.30',
                                      StationID == '9XBB000.86' ~ '9-XBB000.86',
                                      TRUE ~ NA_character_ ))
```

Which stations actually need watershed info?

```{r spatial info already available}
watersheds <- #st_read('D:/evjones/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/Watersheds.gdb', 'AllWatersheds_through2016') %>% 
  st_read('C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/Watersheds.gdb', 'AllWatersheds_through2018') %>% 
  filter(StationID %in% stations$Station_Id)

# so what isn't in there?
missingWatersheds <- filter(stations, ! Station_Id %in% watersheds$StationID) 

```

Bring in somewhat consolidated (Fall 2019 only) bio reports that link StationID to stream order for QA.

```{r stream order}
orderInfo <- readxl::read_excel('C:/HardDriveBackup/ProbMon/2019/RegionalResults_2019_EVJconsolidation.xlsx',sheet = 'EVJ Consolidation')

watersheds <- left_join(watersheds, dplyr::select(orderInfo, REGION:MDCATY), by = c('UID' = 'DEQSITEID')) %>%
  dplyr::select(UID, REGION, MDCATY, everything()) %>% 
  filter(!is.na(UID))
```


```{r}
st_write(points, 'C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/YearlyAnalyses/20192020_StreamStats/rawPoints2.shp')
st_write(watersheds, 'C:/HardDriveBackup/GIS/ProbMonGIS/DelineatedWatersheds/YearlyAnalyses/20192020_StreamStats/rawWatersheds11082021.shp')
```